https://github.com/doocs/advanced-java

https://github.com/Snailclimb/JavaGuide


自我介绍（说说自己的擅长及拿手的技术）
说说treemap和HashMap的区别？
  HashMap：数组方式存储key/value，线程非安全，允许null作为key和value，key不可以重复，value允许重复，不保证元素迭代顺序是按照插入时的顺序，key的hash值是先计算key的hashcode值，然后再进行计算，每次容量扩容会重新计算所以key的hash值，会消耗资源，要求key必须重写equals和hashcode方法;默认初始容量16，加载因子0.75，扩容为旧容量乘2，查找元素快，如果key一样则比较value，如果value不一样，则按照链表结构存储value，就是一个key后面有多个value

  treeMap：基于红黑二叉树的NavigableMap的实现，线程非安全，不允许null，key不可以重复，value允许重复，存入TreeMap的元素应当实现Comparable接口或者实现Comparator接口，会按照排序后的顺序迭代元素，两个相比较的key不得抛出classCastException。主要用于存入元素的时候对元素进行自动排序，迭代输出的时候就按排序顺序输出


HashTable、HashMap和ConcurrentHashMap的区别？
  HashTable：
    1.底层数组+链表实现，无论key还是value都不能为null，线程安全，实现线程安全的方式是在修改数据时锁住整个HashTable，效率低，ConcurrentHashMap做了相关优化
    2.初始size为11，扩容：newsize = olesize*2+1
    3.计算index的方法：index = (hash & 0x7FFFFFFF) % tab.length
  HashMap：
    1.底层数组+链表实现，可以存储null键和null值，线程不安全
    2.初始size为16，扩容：newsize = oldsize*2，size一定为2的n次幂
    3.容针对整个Map，每次扩容时，原来数组中的元素依次重新计算存放位置，并重新插入
    4.插入元素后才判断该不该扩容，有可能无效扩容（插入后如果扩容，如果没有再次插入，就会产生无效扩容）
    5.当Map中元素总数超过Entry数组的75%，触发扩容操作，为了减少链表长度，元素分配更均匀
    6.计算index方法：index = hash & (tab.length – 1)
      HashMap的初始值还要考虑加载因子:
        1.哈希冲突：若干Key的哈希值按数组大小取模后，如果落在同一个数组下标上，将组成一条Entry链，对Key的查找需要遍历Entry链上的每个元素执行equals()比较。
        2.加载因子：为了降低哈希冲突的概率，默认当HashMap中的键值对达到数组大小的75%时，即会触发扩容。因此，如果预估容量是100，即需要设定100/0.75＝134的数组大小。
        3.空间换时间：如果希望加快Key查找的时间，还可以进一步降低加载因子，加大初始大小，以降低哈希冲突的概率
      HashMap和Hashtable都是用hash算法来决定其元素的存储，因此HashMap和Hashtable的hash表包含如下属性：
        1.容量（capacity）：hash表中桶的数量
        2.初始化容量（initial capacity）：创建hash表时桶的数量，HashMap允许在构造器中指定初始化容量
        3.尺寸（size）：当前hash表中记录的数量
        4.负载因子（load factor）：负载因子等于“size/capacity”。负载因子为0，表示空的hash表，0.5表示半满的散列表，依此类推。轻负载的散列表具有冲突少、适宜插入与查询的特点（但是使用Iterator迭代元素时比较慢）
      “负载极限”的默认值（0.75）是时间和空间成本上的一种折中：
        1.较高的“负载极限”可以降低hash表所占用的内存空间，但会增加查询数据的时间开销，而查询是最频繁的操作（HashMap的get()与put()方法都要用到查询）
        2.较低的“负载极限”会提高查询数据的性能，但会增加hash表所占用的内存开销
  ConcurrentHashMap：
    1.底层采用分段的数组+链表实现，线程安全
    2.通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)
    3.Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术
    4.有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁
    5.扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容
    ConcurrentHashMap是使用了锁分段技术来保证线程安全的
      锁分段技术：首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。
      ConcurrentHashMap提供了与Hashtable和SynchronizedMap不同的锁机制。Hashtable中采用的锁机制是一次锁住整个hash表，从而在同一时刻只能由一个线程对其进行操作；而ConcurrentHashMap中则是一次锁住一个桶

HashMap底层如何实现(JDK1.8有所改动)？
  1.为什么用hash表哈希表
    在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)，接下来我们就来看看哈希表是如何实现达到惊艳的常数阶O(1)的。
    解决hash冲突的方法：开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式
  2.HashMap实现原理
    HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。
    initialCapacity默认为16，loadFactory默认为0.75
    h&（length-1）保证获取的index一定在数组范围内
    发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。
  3.为何HashMap的数组长度一定是2的次幂？
    上面的&运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。

说说Hash的一致算法？
  同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

你知道的GC算法和回收策略有哪些？
  GC算法:
    1.标记清除算法
      标记-清除算法分为标记和清除两个阶段。该算法首先从根集合进行扫描，对存活的对象对象标记，标记完毕后，再扫描整个空间中未被标记的对象并进行回收，
      缺点：
        1.效率问题：标记和清除两个过程的效率不高
        2.空间问题：标记和清除两个过程不需要进行对象的移动，并且仅对不存活的对象清理，清理后产生许多不连续的内存碎片
    2.复制算法
      复制算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这种算法适用于对象存活率低的场景，比如新生代，因为研究发现，新生代中的对象每次回收都基本上只有10%左右的对象存活，所以需要复制的对象很少，效率还不错。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效
    3.标记整理算法
      标记整理算法与标记清除算法最显著的区别是：标记清除算法不进行对象的移动，并且仅对不存活的对象进行处理；而标记整理算法会将所有的存活对象移动到一端，并对不存活对象进行处理，因此其不会产生内存碎片
    4.分代收集算法
      不同的对象的生命周期(存活情况)是不一样的，而不同生命周期的对象位于堆中不同的区域，因此对堆内存不同区域采用不同的策略进行回收可以提高 JVM 的执行效率。当代商用虚拟机使用的都是分代收集算法：新生代对象存活率低，就采用复制算法；老年代存活率高，就用标记清除算法或者标记整理算法。Java堆内存一般可以分为新生代、老年代和永久代三个模块，
  垃圾对象判定：
    1.引用计数算法
      给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1，当引用失效时，计数器值就减1，任何时刻计数器都为0的对象就是不可能再被使用的。引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的选择，当Java语言并没有选择这种算法来进行垃圾回收，主要原因是它很难解决对象之间的相互循环引用问题。
    2.根搜索算法
      为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，就证明此对象是不可用的。
垃圾回收器
  1.Serial收集器
    Serial收集器是最基本、发展历史最悠久的收集器。是单线程的收集器。它在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集完成。Serial收集器依然是虚拟机运行在Client模式下默认新生代收集器，对于运行在Client模式下的虚拟机来说是一个很好的选择
  2.ParNew收集器
    ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The Worl、对象分配规则、回收策略等都与Serial 收集器完全一样。ParNew收集器是许多运行在Server模式下的虚拟机中首选新生代收集器，其中有一个与性能无关但很重要的原因是，除Serial收集器之外，目前只有ParNew它能与CMS收集器配合工作。
  3.Parallel Scavenge（并行回收）收集器
    Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器该收集器的目标是达到一个可控制的吞吐量（Throughput）。自适应调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别
  4.Serial Old 收集器
    Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记整理算法。这个收集器的主要意义也是在于给Client模式下的虚拟机使用。
  5.Parallel Old 收集器
    Parallel Old 是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器在1.6中才开始提供。
  6.CMS收集器
    CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务器的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求
    CMS收集器主要优点：并发收集，低停顿。
    CMS三个明显的缺点：
      1.CMS收集器对CPU资源非常敏感。CPU个数少于4个时，CMS对于用户程序的影响就可能变得很大，为了应付这种情况，虚拟机提供了一种称为“增量式并发收集器”的CMS收集器变种。所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想
      2.CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。
      3.CMS是基于“标记-清除”算法实现的收集器，手机结束时会有大量空间碎片产生。
  7.G1收集器
    G1收集器的优势：
    （1）并行与并发
    （2）分代收集
    （3）空间整理 （标记整理算法，复制算法）
    （4）可预测的停顿（G1处处理追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经实现Java（RTSJ）的来及收集器的特征）

CMS的回收步骤
  初始标记 ：在这个阶段，需要虚拟机停顿正在执行的任务，官方的叫法STW(Stop The Word)。这个过程从垃圾回收的"根对象"开始，只扫描到能够和"根对象"直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。
  并发标记 ：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。
  并发预清理 ：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象(可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代)。通过重新扫描，减少下一个阶段"重新标记"的工作，因为下一个阶段会Stop The World。
  重新标记 ：这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从"跟对象"开始向下追溯，并处理对象关联。
  并发清理 ：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。
  并发重置 ：这个阶段，重置CMS收集器的数据结构，等待下一次垃圾回收。

G1内部是如何分区的（region）
  1里面的Region的概念不同于传统的垃圾回收算法中的分区的概念。G1默认把堆内存分为1024个分区，后续垃圾收集的单位都是以Region为单位的。Region是实现G1算法的基础，每个Region的大小相等，通过-XX:G1HeapRegionSize参数可以设置Region的大小

乐观锁和悲观锁？
  1.悲观锁
    总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。
  2.乐观锁
    总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。
  3.两种锁的使用场景
    乐观锁适用于写比较少的情况下；一般多写的场景下用悲观锁就比较合适。
  4.乐观锁常见的两种实现方式
    a.版本号机制
      一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。
    b.CAS算法
      即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数:需要读写的内存值 V;进行比较的值 A;拟写入的新值 B
  5.乐观锁的缺点
    a.ABA 问题
      如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 "ABA"问题。
    b.循环时间长开销大
      自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。
    c.只能保证一个共享变量的原子操作

可重入锁(ReenTrantLock)和Synchronized？
  1.可重入性
    从名字上理解，ReenTrantLock的字面意思就是再进入的锁，其实synchronized关键字所使用的锁也是可重入的，两者关于这个的区别不大。两者都是同一个线程没进入一次，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。
  2.锁的实现
    Synchronized是依赖于JVM实现的，而ReenTrantLock是JDK实现的，有什么区别，说白了就类似于操作系统来控制实现和用户自己敲代码实现的区别。
  3.性能的区别
    在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。
  4.功能区别
    便利性：很明显Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。锁的细粒度和灵活度：很明显ReenTrantLock优于Synchronized
  5.ReenTrantLock独有的能力：
    a.ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。
    b.ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。
    c.ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。
  6.ReenTrantLock实现的原理
    ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

Synchronized优化?
  synchronized的作用主要有三个
    1.确保线程互斥的访问代码
    2.保证共享变量的修改能够及时可见
    3.可以阻止JVM的指令重排序
  synchronized主要有三种应用方式
    1.普通同步方法，锁的是当前实例的对象
    2.静态同步方法，锁的是静态方法所在的类对象
    2.同步代码块，锁的是括号里的对象
  同步代码块
    monitorenter指令插入到同步代码块的开始位置。monitorexit指令插入到同步代码块结束的位置。JVM需要保证每一个monitorenter都有一个monitorexit与之对应。
    任何对象，都有一个monitor与之相关联，当monitor被持有以后，它将处于锁定状态。线程执行到monitorenter指令时，会尝试获得monitor对象的所有权，即尝试获取锁。
  同步方法
    synchronized方法则会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。
  优化
    锁粗化;锁消除;适应性自旋.  增加两种状态:偏向锁,轻量锁
    锁的状态:
      锁的状态共有四种：无锁，偏向锁，轻量锁，重量锁。随着锁的竞争，锁会从偏向锁升级为轻量锁，然后升级为重量锁。锁的升级是单向的，JDK1.6中默认开启偏向锁和轻量锁。
    偏向锁
      引入偏向锁的目的是：为了在无多线程竞争的情况下，尽量减少不必要的轻量锁执行路径。因为经过研究发现，在大部分情况下，锁并不存在多线程竞争，而且总是由一个线程多次获得锁。因此为了减少同一线程获取锁（会涉及到一些耗时的CAS操作）的代价而引入。如果一个线程获取到了锁，那么该锁就进入偏向锁模式，当这个线程再次请求锁时无需做任何同步操作，直接获取到锁。这样就省去了大量有关锁申请的操作，提升了程序性能。
    轻量级锁:
      轻量锁能够提升性能的依据，是基于如下假设：即在真实情况下，程序中的大部分代码一般都处于一种无锁竞争的状态（即单线程环境），而在无锁竞争下完全可以避免调用操作系统层面的操作来实现重量锁。如果打破这个依据，除了互斥的开销外，还有额外的CAS操作，因此在有线程竞争的情况下，轻量锁比重量锁更慢。为了减少传统重量锁造成的性能不必要的消耗，才引入了轻量锁。当关闭偏向锁功能 或者 多个线程竞争偏向锁导致升级为轻量锁，则会尝试获取轻量锁。
    重量级锁
      重量级锁通过对象内部的监视器（Monitor）来实现，而其中monitor本质上是依赖于低层操作系统的 Mutex Lock实现。操作系统实现线程切换，需要从用户态切换到内核态，切换成本非常高
    适应性自旋
      在轻量级锁获取失败时，为了避免线程真实的在系统层面被挂起，还会进行一项称为自旋锁的优化手段。线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准确，虚拟机会变得越来越聪明。
    锁粗化
      粗化锁就是将连续的同步操作连在一起，粗化为一个范围更大的锁
    锁消除
      JVM在进行JIT编译时，通过对上下文的扫描，JVM检测到不可能存在共享数据的竞争，如果这些资源有锁，那么会消除这些资源的锁。这样可以节省毫无意义的锁请求时间。

CountDownLaunch和Cylicbarrior的区别以及分别是在哪样场景下使用的？
  CountDownLatch : 一个线程(或者多个)， 等待另外N个线程完成某个事情之后才能执行。   CyclicBarrier        : N个线程相互等待，任何一个线程完成之前，所有的线程都必须等待。
  这样应该就清楚一点了，对于CountDownLatch来说，重点是那个“一个线程”, 是它在等待， 而另外那N的线程在把“某个事情”做完之后可以继续等待，可以终止。而对于CyclicBarrier来说，重点是那N个线程，他们之间任何一个没有完成，所有的线程都必须等待

  CountDownLatch 是计数器, 线程完成一个就记一个, 就像 报数一样, 只不过是递减的.
  而CyclicBarrier更像一个水闸, 线程执行就想水流, 在水闸处都会堵住, 等到水满(线程到齐)了, 才开始泄流

Http和Https的区别以及Https加密的方式？
  HTTPS和HTTP的区别主要如下：
  1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
  2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
  3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
  4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全
    这套证书其实就是一对公钥和私钥，如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。

几种线程池区别
  1.newCachedThreadPool
    创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
    这种类型的线程池特点是：
      工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。
      如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。
      在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。
  2.newFixedThreadPool
    创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。
  3.newSingleThreadExecutor
    创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。
  4.newScheduleThreadPool
    创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行。

Callable和Future
  创建线程的2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。
  这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。
  如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。

  Callable接口代表一段可以调用并返回结果的代码;Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。

ABC三个线程如何保证顺序执行
public static void main(String[] args) throws InterruptedException {
      final Thread t1 = new Thread(new Runnable() {
          public void run() {
              System.out.println(Thread.currentThread().getName() + " run 1");
          }
      }, "T1");
      final Thread t2 = new Thread(new Runnable() {
          public void run() {
              System.out.println(Thread.currentThread().getName() + " run 2");
              try {
                  t1.join(10);
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          }
      }, "T2");
      ExecutorService executor = Executors.newSingleThreadExecutor();
              executor.submit(t1);
              executor.submit(t2);
              executor.submit(t3);
              executor.shutdown();

JVM的内存结构
  VM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配；方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)；栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。
  1.Java堆（Heap）
    Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存
  2.方法区
    方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。
  3.程序计数器
    程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。
  4.JVM栈
    与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。
  5.本地方法栈
    本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务

强引用、软引用、弱引用和虚引用
  1.强引用
    以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于必不可少的生活用品，垃圾回收器绝不会回收它。当内存空 间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。
  2.软引用
    如果一个对象只具有软引用，那就类似于可有可物的生活用品。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。
    软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。
  3.弱引用
    如果一个对象只具有弱引用，那就类似于可有可物的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。
  4.虚引用
    “虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。
sleep和wait的区别
  sleep()方法导致了程序暂停执行指定的时间，让出cpu该其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。在调用sleep()方法的过程中，线程不会释放对象锁。

  而当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。

Java中notify和notifyAll的区别
  notify和notifyAll之间的关键区别在于notify（）只会唤醒一个线程，而notifyAll方法将唤醒所有线程。

双亲委托模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需要加载的类）时，子加载器才会尝试自己去加载。
使用双亲委托机制的好处是：能够有效确保一个类的全局唯一性，当程序中出现多个限定名相同的类时，类加载器在执行加载时，始终只会加载其中的某一个类。

Java类加载的过程
1、加载
简单的说，类加载阶段就是由类加载器负责根据一个类的全限定名来读取此类的二进制字节流到JVM内部，并存储在运行时内存区的方法区，然后将其转换为一个与目标类型对应的java.lang.Class对象实例（Java虚拟机规范并没有明确要求一定要存储在堆区中，只是hotspot选择将Class对戏那个存储在方法区中），这个Class对象在日后就会作为方法区中该类的各种数据的访问入口。
2、链接
链接阶段要做的是将加载到JVM中的二进制字节流的类数据信息合并到JVM的运行时状态中，经由验证、准备和解析三个阶段。
1）、验证
验证类数据信息是否符合JVM规范，是否是一个有效的字节码文件，验证内容涵盖了类数据信息的格式验证、语义分析、操作验证等。
格式验证：验证是否符合class文件规范
语义验证：检查一个被标记为final的类型是否包含子类；检查一个类中的final方法视频被子类进行重写；确保父类和子类之间没有不兼容的一些方法声明（比如方法签名相同，但方法的返回值不同）
操作验证：在操作数栈中的数据必须进行正确的操作，对常量池中的各种符号引用执行验证（通常在解析阶段执行，检查是否通过富豪引用中描述的全限定名定位到指定类型上，以及类成员信息的访问修饰符是否允许访问等）
2）、准备
为类中的所有静态变量分配内存空间，并为其设置一个初始值（由于还没有产生对象，实例变量不在此操作范围内）
被final修饰的静态变量，会直接赋予原值；类字段的字段属性表中存在ConstantValue属性，则在准备阶段，其值就是ConstantValue的值
3）、解析
将常量池中的符号引用转为直接引用（得到类或者字段、方法在内存中的指针或者偏移量，以便直接调用该方法），这个可以在初始化之后再执行。
可以认为是一些静态绑定的会被解析，动态绑定则只会在运行是进行解析；静态绑定包括一些final方法(不可以重写),static方法(只会属于当前类)，构造器(不会被重写)
3、初始化
将一个类中所有被static关键字标识的代码统一执行一遍，如果执行的是静态变量，那么就会使用用户指定的值覆盖之前在准备阶段设置的初始值；如果执行的是static代码块，那么在初始化阶段，JVM就会执行static代码块中定义的所有操作。
所有类变量初始化语句和静态代码块都会在编译时被前端编译器放在收集器里头，存放到一个特殊的方法中，这个方法就是<clinit>方法，即类/接口初始化方法。该方法的作用就是初始化一个中的变量，使用用户指定的值覆盖之前在准备阶段里设定的初始值。任何invoke之类的字节码都无法调用<clinit>方法，因为该方法只能在类加载的过程中由JVM调用。
如果父类还没有被初始化，那么优先对父类初始化，但在<clinit>方法内部不会显示调用父类的<clinit>方法，由JVM负责保证一个类的<clinit>方法执行之前，它的父类<clinit>方法已经被执行。
JVM必须确保一个类在初始化的过程中，如果是多线程需要同时初始化它，仅仅只能允许其中一个线程对其执行初始化操作，其余线程必须等待，只有在活动线程执行完对类的初始化操作之后，才会通知正在等待的其他线程。
4.使用
5.卸载

Spring IOC如何管理Bean之间的依赖关系，怎么样避免循环依赖？
Spring先是用构造实例化Bean对象，此时Spring会将这个实例化结束的对象放到一个Map中，并且Spring提供了获取这个未设置属性的实例化对象引用的方法。 结合我们的实例来看，当Spring实例化了TestA、TestB、TestC后，紧接着会去设置对象的属性，此时TestA依赖TestB，就会去Map中取出存在里面的单例TestB对象，以此类推


SpringBean创建过程中的设计模式？说说AOP的实现原理？
  1.工厂方法
  应用程序有自己的工厂对象来创建bean.如果将应用程序自己的工厂对象交给Spring管理,那么Spring管理的就不是普通的bean,而是工厂Bean。
螃蟹就以工厂方法中的静态方法为例讲解一下
  2.单例模式
  spring中的单例模式完成了后半句话，即提供了全局的访问点BeanFactory。但没有从构造器级别去控制单例，这是因为spring管理的是是任意的java对象。
  核心提示点：Spring下默认的bean均为singleton，可以通过singleton=“true|false” 或者 scope=“？”来指定
  3.代理
    为其他对象提供一种代理以控制对这个对象的访问。  从结构上来看和Decorator模式类似，但Proxy是控制，更像是一种对功能的限制，而Decorator是增加职责。 pring的Proxy模式在aop中有体现
  4.观察者
    pring中Observer模式常用的地方是listener的实现。如ApplicationListener。 


自我介绍，聊下自己认为做得很好的项目！
InnoDB支持的四种事务隔离级别名称是什么？ 之间的区别是什么？
MySQL隔离级别是什么？
说说事务的特性？
讲讲对慢查询的分析？
你理解的BTree机制？
有哪些MySQL常用的优化方法？

B+树索引和Hash索引之间的区别？
Spring IOC如何管理Bean之间的依赖关系，怎么样避免循环依赖？
SpringBean创建过程中的设计模式？说说AOP的实现原理？
Tomcat的基本架构是什么？


自己项目中的总结的并发经验说说MySQL的锁并发？
加锁的机制是什么？
高并发场景下如何防止死锁，保证数据的一致性？
集群和负载均衡的算法与实现？
说说分库与分表设计？
分库分表带来的分布式困境与对应之策有哪些？
Redis和Setnx命令使如何实现分布式锁的？
使用Redis怎么进行异步队列？会有什么缺点？
缓存击穿的概念和解决方案?
Redis的数据结构？
线程模型？
Redis的数据淘汰机制？
Redis的数据一致性问题MQ底层原理的实现？
阻塞队列不用Java提供的该怎么实现？
讲讲负载均衡的原理？
如何实现高并发环境下的削峰、限流？


讲讲项目中用到的中间件(Dubbo/MQ/Zookeeper/Redis/Kafka)？
什么情况下会造成雪崩？该怎么避免这种情况？
高并发架构的设计思路？
以前的项目中遇到的问题和解决策略？
生活中遇到过哪些挫折？最后怎么解决的?


一面
hashmap与concurrenthashmap的区别
HashMap如何解决Hash冲突
my sql 索引类别
什么是覆盖索引
b+树和b树的区别
为什么选用自增量作为主键索引
my sql如何优化查询
my sql如何在RR隔离级别下避免幻读问题：间隙锁
my sql范式和反范式的区别以及彼此的优缺点
AOF如何缩减自身文件大小
AOF缩减自身文件大小的时候，数据库来了新的操作怎么办？
多线程了解么？
死锁条件以及破坏死锁条件的方法
volatile做什么用的，如何实现可见性的
volatile和atomic的区别
atomic底层是如何实现的
二面
表锁 行锁 乐观锁 悲观锁的特点和区别
并发工具包有哪些，具体怎么用
Lock和Synchronized的区别
分布式下redis如何保证线程安全
Kafka讲一讲
Docker平时怎么使用的
几种线程池区别
Kafka如何解决数据堆积
kafka消息的存储机制
如何用kafka保证消息的有序性
kafka如何保证并发情况下消息只被消费一次
三面
redis用的哪个版本
如何搭建redis集群
redis如何主从同步
redis分布式锁注意事项
redis持久化的方式以及区别
redis持久化方式及区别
my sql数据量多大的时候需要分表
my sql常用的存储引擎及区别
死锁的条件及应对措施
zookeeper的作用：分布式锁、注册服务中心
zookeeper如何实现分布式锁、其他分布式锁怎么实现
分布式事务的解决方案
单点登录怎么实现
秒杀系统怎么来实现


1.HashMap的源码，实现原理，JDK8中对HashMap做了怎样的优化。
2.HaspMap扩容是怎样扩容的，为什么都是2的N次幂的大小。
3.HashMap，HashTable，ConcurrentHashMap的区别。
4.极高并发下HashTable和ConcurrentHashMap哪个性能更好，为什么，如何实现的。
5.HashMap在高并发下如果没有处理线程安全会有怎样的安全隐患，具体表现是什么。
6.java中四种修饰符的限制范围。
7.Object类中的方法。
8.接口和抽象类的区别，注意JDK8的接口可以有实现。
9.动态代理的两种方式，以及区别。
10.Java序列化的方式。
11.传值和传引用的区别，Java是怎么样的，有没有传值引用。
12.一个ArrayList在循环过程中删除，会不会出问题，为什么。
13.@transactional注解在什么情况下会失效，为什么。

1.B+树
2.快速排序，堆排序，插入排序（其实八大排序算法都应该了解
3.一致性Hash算法，一致性Hash算法的应用


1.JVM的内存结构。
2.JVM方法栈的工作过程，方法栈和本地方法栈有什么区别。
3.JVM的栈中引用如何和堆中的对象产生关联。
4.可以了解一下逃逸分析技术。
5.GC的常见算法，CMS以及G1的垃圾回收过程，CMS的各个阶段哪两个是Stop the world的，CMS会不会产生碎片，G1的优势。
6.标记清除和标记整理算法的理解以及优缺点。
7.eden survivor区的比例，为什么是这个比例，eden survivor的工作过程。
8.JVM如何判断一个对象是否该被GC，可以视为root的都有哪几种类型。
9.强软弱虚引用的区别以及GC对他们执行怎样的操作。
10.Java是否可以GC直接内存。
11.Java类加载的过程。
12.双亲委派模型的过程以及优势。
13.常用的JVM调优参数。
14.dump文件的分析。
15.Java有没有主动触发GC的方式（没有）。

1.Java实现多线程有哪几种方式。
2.Callable和Future的了解。
3.线程池的参数有哪些，在线程池创建一个线程的过程。
4.volitile关键字的作用，原理。
5.synchronized关键字的用法，优缺点。
6.Lock接口有哪些实现类，使用场景是什么。
7.可重入锁的用处及实现原理，写时复制的过程，读写锁，分段锁（ConcurrentHashMap中的segment）。
8.悲观锁，乐观锁，优缺点，CAS有什么缺陷，该如何解决。
9.ABC三个线程如何保证顺序执行。
10.线程的状态都有哪些。
11.sleep和wait的区别。
12.notify和notifyall的区别。
13.ThreadLocal的了解，实现原理。

1.常见的数据库优化手段
2.索引的优缺点，什么字段上建立索引
3.数据库连接池。
4.durid的常用配置。


1.TCP，UDP区别。
2.三次握手，四次挥手，为什么要四次挥手。
3.长连接和短连接。
4.连接池适合长连接还是短连接。


1.观察者模式
2.代理模式
3.单例模式，有五种写法，可以参考文章单例模式的五种实现方式
4.可以考Spring中使用了哪些设计模式

1.分布式事务的控制。
2.分布式锁如何设计。
3.分布式session如何设计。
4.dubbo的组件有哪些，各有什么作用。
5.zookeeper的负载均衡算法有哪些。
6.dubbo是如何利用接口就可以通信的。


1.redis和memcached的区别。
2.redis支持哪些数据结构。
3.redis是单线程的么，所有的工作都是单线程么。
4.redis如何存储一个String的。
5.redis的部署方式，主从，集群。
6.redis的哨兵模式，一个key值如何在redis集群中找到存储在哪里。
7.redis持久化策略。

1.SpringMVC的Controller是如何将参数和前端传来的数据一一对应的。
2.Mybatis如何找到指定的Mapper的，如何完成查询的。
3.Quartz是如何完成定时任务的。
4.自定义注解的实现。
5.Spring使用了哪些设计模式。
6.Spring的IOC有什么优势。
7.Spring如何维护它拥有的bean。

1.JDK8的新特性，流的概念及优势，为什么有这种优势。
2.区块链了解
3.如何设计双11交易总额面板，要做到高并发高可用。
