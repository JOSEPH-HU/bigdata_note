1.spark shuffle过程
  spark shuffle相对比较简单，因为不需要全局有序，所以没有那么多排序合并操作，spark shuffle分为write和read两个过程
  a.shuffle write
    shuffle write的处理逻辑会放到该ShuffleMapStage的最后（因为spark以shuffle发生与否来划分stage，也就是宽依赖），final RDD的每一条记录都会写到对应的分区缓存区bucket，
    1.上图中有2个cpu，可以同时运行两个shuffleMapTask
    2.每个task将写一个buket缓冲区，缓冲区的数量和reduce任务的数量相等
    3.每个buket缓冲区会生成一个对应的shuffleBlockFile
    4.shuffleMapTask如何决定数据被写入到那个缓冲区呢？这个是跟partition算法有关系，这个分区算法可以是hash，也可以是range
    5.最终产生的shuffleBlockFIle会有多少呢？就是shufflemaptask乘以reduce的数量，这个是非常巨大的，那么有没有办法解决生成文件过多的问题呢？开启FileConsolidation即可
    在同一核CPU执行先后执行的ShuffleMapTask可以共用一个bucket缓冲区，然后写到同一份ShuffleFile里去，上图所示的ShuffleFile实际上是用多个ShuffleBlock构成，那么，那么每个worker最终生成的文件数量，变成了cpu核数乘以reduce任务的数量，大大缩减了文件量。
  b.Shuffle read
    那么Shuffle Read发送的时机是什么？是要等所有ShuffleMapTask执行完，再去fetch数据吗？理论上，只要有一个 ShuffleMapTask执行完，就可以开始fetch数据了，实际上，spark必须等到父stage执行完，才能执行子stage，所以，必须等到所有 ShuffleMapTask执行完毕，才去fetch数据。fetch过来的数据，先存入一个Buffer缓冲区，所以这里一次性fetch的FileSegment不能太大，当然如果fetch过来的数据大于每一个阀值，也是会spill到磁盘的。
  总结：
    1、Hadoop的有一个Map完成，Reduce便可以去fetch数据了，不必等到所有Map任务完成，而Spark的必须等到父stage完成，也就是父stage的map操作全部完成才能去fetch数据。
    2、Hadoop的Shuffle是sort-base的，那么不管是Map的输出，还是Reduce的输出，都是partion内有序的，而spark不要求这一点。
    3、Hadoop的Reduce要等到fetch完全部数据，才将数据传入reduce函数进行聚合，而spark是一边fetch一边聚合。
2.spark join处理倾斜
// reduceBykey加随机数避免数据倾斜
val preRDD = rdd.map(x=>{
Random random = new Random()
int pre = random.nextInt(100);
(pre+"_"+x.1, x._2)  //1_hello  2_hello
})
val firReduce = preRDD.reduceBykey(+)
val secRDD = firReduce.map(x=>{
val key = x.1.split("_")[1]
(key, x._2)
})
val secReduce = secRDD.reduceBykey(+)


// 小数据量与大数据量join时避免数据倾斜
val rdd1 = rdd1.collect()
val broadcastRdd1 = sc.broadcast(rdd1)
rdd2.map(x=>{
val rdd1Data = broadcastRdd1.value()
val map = HashMap()
for (data <- rdd1Value){
  map.append(data.1,data.2)
}
val rdd1Value = map.get(x._1)
(x.1, (x.2, rdd1Value))
})


// 采样倾斜key并分拆join操作
val sampleRDD = rdd1.sample(false,0.1)
topIds = sampleRDD.map((.1, 1)).reduceBykey(+).sortBy(.2,false).map(.1).take(100).collect()
val filterRDD1 = rdd1.filter(line=>{
topIds.contains(line)
})
val commonRDD1 = rdd1.filter(line=>{
!topIds.contains(line)
})
val filterRDD2 = rdd2.filter(line=>{
topIds.contains(line)
}).flatMap(x=>{
val list = BufferList();
for (i <- 1 to 100){
  list += (i+"_"+x.1, x._2)
}
list
})
val joinedRDD1 = filterRDD1.map(x=>{
Random random = new Random()
int pre = random.nextInt()
(pre+"_"+x.1, x._2)
})
val joinedRDD1 = joinedRDD1.join(filterRDD2)
val joinedRDD2 = commonRDD1.join(rdd2)
val joinedRDD = joinedRDD1.union(joinedRDD2)

3.topn
val topNResult1: RDD[(String, Seq[Int])] = mapredRDD.groupByKey().map(tuple2 => {
            //获取values里面的topN
            val topn = tuple2._2.toList.sorted.takeRight(topN.value).reverse
            (tuple2._1, topn)
        })

        println("+---+---+ 使用groupByKey获取TopN的结果：")
        println(topNResult1.collect().mkString("\n"))

        //2.使用两阶段聚合，先使用随机数进行分组聚合取出局部topn,再聚合取出全局topN的数据
        val topNResult2: RDD[(String, List[Int])] = mapredRDD.mapPartitions(iterator => {
            iterator.map(tuple2 => {
                ((Random.nextInt(10), tuple2._1), tuple2._2)
            })
        }).groupByKey().flatMap({
            //获取values中的前N个值 ，并返回topN的集合数据
            case ((_, key), values) =>
                values.toList.sorted.takeRight(topN.value).map(value => (key, value))
        }).groupByKey().map(tuple2 => {
            val topn = tuple2._2.toList.sorted.takeRight(topN.value).reverse
            (tuple2._1, topn)
        })
        println("+---+---+ 使用两阶段集合获取TopN的结果：")
        println(topNResult2.collect().mkString("\n"))

        //3、使用aggregateByKey获取topN的记录
        val topNResult3: RDD[(String, List[Int])] = mapredRDD.aggregateByKey(ArrayBuffer[Int]())(
            (u, v) => {
                u += v
                u.sorted.takeRight(topN.value)
            },
            (u1, u2) => {
                //对任意的两个局部聚合值进行聚合操作，可以会发生在combiner阶段和shuffle之后的最终的数据聚合的阶段
                u1 ++= u2
                u1.sorted.takeRight(topN.value)
            }
        ).map(tuple2 => (tuple2._1, tuple2._2.toList.reverse))

4.driver的功能是什么
  1.一个spark作业运行时包括一个driver进程，也是作业的主进程，具有main函数，并且sparkContext的实例，是程序的入口
  2.功能：负责集群申请资源，向master注册信息，负责作业调度，负责作业的解析、生成stage并调度task到executor上，包括DAGScheduler，TaskScheduler。
5.spark为什么比mapreduce快？
  a.基于内存的计算，减少低效的磁盘交互
  b.高效的调度算法，基于DAG
  c.容错机制Linage（血统），精华部分就是DAG和Lingae
6.容错原理
  在容错机制中，如果一个节点死机，而且运算窄依赖，则只要把丢失的父RDD分区重新计算，不依赖其他节点。而宽依赖需要父RDD的所有分区都存在，重算就很昂贵。在窄依赖中，在子RDD的分区丢失、重算父RDD分区时，父RDD相应分区的所有数据都是子RDD分区数据，并不存在冗余计算。在宽依赖情况下，丢失一个子RDD分区重算的是每个父RDD的每个分区的所有数据并不是都给丢失的子RDD的分区用，会有一部分数据相当于对应的是未丢失的子RDD分区中需要的数据，这样就会产生冗余计算开销，这也是宽依赖开销更大的原因。

7.cache和checkpoint的区别
  缓存把RDD计算出来然后放在内存中，但是RDD的依赖关系不能丢掉，当某个点的execute宕机，上面cache的RDD就会丢掉，需要通过依赖关系重新计算出来，不同的是，checkpoint是把RDD保存在HDFS中，是多副本可靠存储，所以依赖链就可以丢掉，就斩断依赖关系，是通过复制实现的高容错，但是有一点要注意，因为checkpoint是需要把job重新从头算一遍，最好先cache一下。chechpoint就可以直接保存缓存中的RDD，就不需要重头计算一遍，对性能有极大的帮助.
  val data = sc.textFile("/tmp/spark/1.data").cache() // 注意要cache
  sc.setCheckpointDir("/tmp/spark/checkpoint")
  data.checkpoint
  data.count
  为什么在checkpoint之前要用cache呢？
    有与在任务结束的时候，会在起一个job进行checkpoint，这样会运算两次
8.RDD有那些缺陷
  1.不支持细粒度的写和更新操作，spark写数据是粗粒度，就是批量写入数据，为了提高效率，但是读数据是细粒度的也就是说可以一条一条的读。
  2.不支持增量迭代计算，Flink支持
9.rdd有几种操作类型
  1）transformation，rdd由一种转为另一种rdd2）action，3）cronroller，crontroller是控制算子,cache,persist，对性能和效率的有很好的支持三种类型，
10.Spark程序执行，有时候默认为什么会产生很多task，怎么修改默认task执行个数？
  参数可以通过spark_home/conf/spark-default.conf配置文件设置:spark.sql.shuffle.partitions=50 spark.default.parallelism=10第一个是针对spark sql的task数量第二个是非spark sql程序设置生效
11.结构化数据流
  a.结构化数据流是一个可拓展、容错的。基于sparksql执行的流处理引擎。使用小量的静态数据模拟流处理，伴随流数据的到来，Spark SQL引擎会逐渐连续处理数据并且更新结果到最终的Table中。你可以在Spark SQL上引擎上使用DataSet/DataFrame API处理流数据的聚集，事件窗口，和流与批次的连接操作等。最后Structured Streaming 系统快速，稳定，端到端的恰好一次保证，支持容错的处理。解决乱序数据
  b."Output"是写入到外部存储的写方式，写入方式有不同的模式
    Complete Mode:整个更新的结果表将写入外部存储器。由存储连接器决定如何处理整个表的写入。支持聚合查询
    Append Mode:自上次触发后，只有结果表中附加的新行才会写入外部存储器。这仅适用于预计结果表中的现有行不会更改的查询。只有select、where、map、flatmap、filter、join等的查询将支持追加模式。
    Update Mode:只有自上一个触发器以来在结果表中更新的行才会写入外部存储器（从spark 2.1.1开始可用）。请注意，这与完整模式不同，因为此模式只输出自上一个触发器以来已更改的行。如果查询不包含聚合，则等同于追加模式。

    Queries with aggregation:
      Aggregation on event-time with watermark:Append, Update, Complete
      Other aggregations:Complete, Update
    Queries with mapGroupsWithState:Update
    Queries with flatMapGroupsWithState:
      Append operation mode:Append
      Update operation mode:Update
    Queries with joins:Append
    Other queries:Append, update
  c.容错语义
    只交付一次端到端语义是结构化流设计背后的关键目标之一。为了实现这一点，我们设计了结构化的流媒体源、接收器和执行引擎，以便可靠地跟踪处理的确切进度，以便通过重新启动和/或重新处理来处理任何类型的故障。假设每个流源都有偏移量（类似于Kafka偏移量或Kinesis序列号），以跟踪流中的读取位置。引擎使用检查点和提前写入日志来记录每个触发器中正在处理的数据的偏移范围。流水槽设计成幂等处理后处理。同时，使用可重放源和等量汇点，结构化流可以确保在任何故障下端到端的语义都是一次性的。
  d.什么是幂等操作
    幂等操作的特点就是任意多次执行产生的影响均与一次执行的影响相同;方法一、单次支付请求，也就是直接支付了，不需要额外的数据库操作了，这个时候发起异步请求创建一个唯一的ticketId，就是门票，这张门票只能使用一次就作废，具体步骤如下：
    异步请求获取门票
    调用支付，传入门票
    根据门票ID查询此次操作是否存在，如果存在则表示该操作已经执行过，直接返回结果；如果不存在，支付扣款，保存结果
    返回结果到客户端
    如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的

    方法二、分布式环境下各个服务相互调用
    这边就要举例我们的系统了，我们支付的时候先要扣款，然后更新订单，这个地方就涉及到了订单服务以及支付服务了。
    用户调用支付，扣款成功后，更新对应订单状态，然后再保存流水。
    而在这个地方就没必要使用门票ticketId了，因为会比较闲的麻烦
    （支付状态：未支付，已支付）
    步骤：
    1、查询订单支付状态
    2、如果已经支付，直接返回结果
    3、如果未支付，则支付扣款并且保存流水
    4、返回支付结果
    如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的
    对于做过支付的朋友，幂等，也可以称之为冲正，保证客户端与服务端的交易一致性，避免多次扣款
    e.满足水印清除聚合状态
      1.输出的模式是append或者更新
      2.聚合必须有事件事件的列或者基于事件的列
      3.水印用的时间戳必须和聚合的时间戳一致
      4.水印调用必须在聚合之前
    f.水印聚合语义保证
      1.水印延迟（用水印设置）为“2小时”，保证引擎不会丢弃任何延迟时间小于2小时的数据。也就是说，任何比最新处理的数据晚2小时（就事件时间而言）以内的数据都保证被聚合。
      2.但是，担保只在一个方向上是严格的。延迟超过2小时的数据不一定会被删除；它可能会被聚合，也可能不会被聚合。数据越晚，引擎处理数据的可能性就越小。
    g.join操作
      left  right
      static static all join
      stream static Inner(Supported, not stateful);Left Outer(Supported, not stateful)
      static stream Inner(Supported, not stateful);Right Outer(Supported, not stateful)
      stream stream Inner(Supported, optionally specify watermark on both sides + time constraints for state cleanup);Left Outer(Conditionally supported, must specify watermark on right + time constraints for correct results, optionally specify watermark on left for all state cleanup);Right Outer(Conditionally supported, must specify watermark on left + time constraints for correct results, optionally specify watermark on right for all state cleanup)
    k.ForeachBatch
      streamingDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>
      // Transform and write batchDF
      }.start()
      注意:1.默认情况下，foreachbatch至少提供一次写入保证。但是，您可以使用提供给函数的batchID作为消除重复输出并获得一次性保证的方法。2.foreachbatch不使用连续处理模式，因为它从根本上依赖于流式查询的微批处理执行。如果以连续模式写入数据，请改用foreach。
    m.Foreach
    streamingDatasetOfString.writeStream.foreach(
    new ForeachWriter[String] {

    def open(partitionId: Long, version: Long): Boolean = {
    // Open connection
    }

    def process(record: String): Unit = {
    // Write string to connection
    }

    def close(errorOrNull: Throwable): Unit = {
    // Close the connection
    }
    }
    ).start()
    注意:open（）方法中的partitionid和epochid可用于在失败导致重新处理某些输入数据时对生成的数据进行重复数据消除。这取决于查询的执行模式。如果流式查询是在微批处理模式下执行的，那么由一个唯一元组（分区_id，epoch_id）表示的每个分区都保证具有相同的数据。因此，（partition_id，epoch_id）可以用于消除重复和/或事务性提交数据，并实现一次性保证。但是，如果流式查询是在连续模式下执行的，则此保证不适用，因此不应用于重复数据消除。
  n.Triggers
  // Default trigger (runs micro-batch as soon as it can)
df.writeStream
.format("console")
.start()

// ProcessingTime trigger with two-seconds micro-batch interval
df.writeStream
.format("console")
.trigger(Trigger.ProcessingTime("2 seconds"))
.start()

// One-time trigger
df.writeStream
.format("console")
.trigger(Trigger.Once())
.start()

// Continuous trigger with one-second checkpointing interval
df.writeStream
.format("console")
.trigger(Trigger.Continuous("1 second"))
.start()
j.Continuous Processing
  连续处理是Spark 2.3中引入的一种新的实验性流式执行模式，它可以实现低（~1 ms）端到端延迟，并至少保证一次容错。将其与默认的微批处理引擎进行比较，默认微批处理引擎可以实现一次完全保证，但最多可实现~100毫秒的延迟。对于某些类型的查询（在下面讨论），您可以选择在不修改应用程序逻辑的情况下执行它们的模式（即，不更改数据帧/数据集操作）。
k.withWatermark与mapGroupsWithState的关系
不管是基于watermark的窗口计算还是自维护的状态流，它们都是有状态的，watermark只是规定了数据进入“状态”（有资格参与状态计算）的条件，并没有（也不适合）声明状态的“退出”机制。对于watermark的窗口计算来说，它们的“退出”机制是：如果最近某个还处于active状态的窗口它的EndTime比当前批次中最新的一个事件时间减去watermark规定的阈值还要“早”，说明这个窗口所有的数据都就绪了，不会再被更新了，就可以把正式“decommission”了。由于这个逻辑对于watermark的窗口计算来说是通行的， 所以被Spark封装在窗口计算中，对开发人员是透明的，但是对于自维护的状态来说“退出”机制是要根据实际情况进行处理的，因此必须要由开发员人员通过编码来实现，这其中除了业务逻辑上决定的“主动”退出（例如接收到了某类session关闭的消息）之外，还需要有一种“保底”的推出机制：状态超时，对于某些有状态的流，可能并没有对应的关闭消息，可以约定在多长时间内没有收到消息就认定状态终结了，那这时就是基于时间阈值的判断，那就又会涉及到是基于事件时间还是处理时间，显然，Spark是同时支持两种模式的，只是有一点会让新人疑惑的是：在基于事件时间的有状态的流计算上，在API层面“似乎”没有给开发人员一个声明“哪个字段是事件时间”的地方，转而是这样约定的：如果开发人员需要开发基于事件时间的有状态的流计算，则必须使用watermark机制，对应到代码层面就是，当你使用mapGroupsWithState(GroupStateTimeout.EventTimeTimeout())(yourGroupStateUpdateFunc)时，前面一定要先声明withWatermark("yourEnenTimeColumnName", yourWatermarkDuration)
12.Datasets and DataFrames区别
  Dataset可以认为是DataFrame的一个特例，主要区别是Dataset每一个record存储的是一个强类型值而不是一个Row。DataFrame是一个组织成命名列的数据集,因此具有如下三个特点：
    1.DataSet可以在编译时检查类型;并且是面向对象的编程接口。
    2.DataFrame是面向Spark SQL的接口。
    3.DataFrame和DataSet可以相互转化， df.as[ElementType] 这样可以把DataFrame转化为DataSet， ds.toDF() 这样可以把DataSet转化为DataFrame。
13.Bucketing, Sorting and Partitioning
  peopleDF.write.bucketBy(42, "name").sortBy("age").saveAsTable("people_bucketed")
  usersDF.write.partitionBy("favorite_color").format("parquet").save("namesPartByColor.parquet")
  usersDF
  .write
  .partitionBy("favorite_color")
  .bucketBy(42, "name")
  .saveAsTable("users_partitioned_bucketed")
14.spark sql优化
  spark.sql.inMemoryColumnarStorage.compressed	true
  spark.sql.inMemoryColumnarStorage.batchSize 10000
  spark.sql.files.maxPartitionBytes 134217728 (128 MB)
  spark.sql.autoBroadcastJoinThreshold 10485760 (10 MB)
  spark.sql.shuffle.partitions 200

  import org.apache.spark.sql.functions.broadcast
broadcast(spark.table("src")).join(spark.table("records"), "key").show()
15.spark streaming的背压机制
  对于 Receiver-based 数据接收器可以通过park.streaming.receiver.maxRate来设置每秒接受的最大记录数；对于 Direct Approach 的数据接收，我们可以通过配置 spark.streaming.kafka.maxRatePerPartition 参数来限制每次作业中每个 Kafka 分区最多读取的记录条数。这种方法虽然可以通过限制接收速率，来适配当前的处理能力。
  如果用户配置了 spark.streaming.receiver.maxRate 或 spark.streaming.kafka.maxRatePerPartition，那么最后到底接收多少数据取决于三者的最小值。也就是说每个接收器或者每个 Kafka 分区每秒处理的数据不会超
  问题：1.需要事先估计好集群的处理速度以及消息数据的产生速度；2.修改完相关参数之后，我们需要手动重启 Spark Streaming 应用程序；3.如果当前集群的处理能力高于我们配置的 maxRate，而且 producer 产生的数据高于 maxRate，这会导致集群资源利用率低下，而且也会导致数据不能够及时处理。

  为了实现自动调节数据的传输速率，在原有的架构上新增了一个名为 RateController 的组件，这个组件继承自 StreamingListener，其监听所有作业的 onBatchCompleted 事件，并且基于 processingDelay 、schedulingDelay 、当前 Batch 处理的记录条数以及处理完成事件来估算出一个速率；这个速率主要用于更新流每秒能够处理的最大记录的条数。速率估算器（RateEstimator）可以又多种实现，不过目前的 Spark 2.2 只实现了基于 PID 的速率估算器。
16.Spark-Streaming获取kafka数据的两种方式-Receiver与Direct的方式
  一、基于Receiver的方式
    使用receiver来获取数据，receiver是使用kafka的高层次Consumer api来实现，receiver从kafka中获取的数据都是存储在spark上的excutor的内存上，然后spark streaming启动job会去处理那些数据.然而，默认配置下，这种方式可能会应为底层的失败而丢失数据。如果启用数据零丢失，就必须启动预写日志机制(WAL),该机制会同步地接受到的kafka数据写入到hdfs上，所以底层失败，也可以使用预写日志中的数据恢复.
    需要注意的点:
      1.Kafka中的topic的partition，与Spark中的RDD的partition是没有关系的。所以，在KafkaUtils.createStream()中，提高partition的数量，只会增加一个Receiver中，读取partition的线程的数量。不会增加Spark处理数据的并行度。
      2.可以创建多个Kafka输入DStream，使用不同的consumer group和topic，来通过多个receiver并行接收数据。
      3.如果基于容错的文件系统，比如HDFS，启用了预写日志机制，接收到的数据都会被复制一份到预写日志中。因此，在KafkaUtils.createStream()中，设置的持久化级别是StorageLevel.MEMORY_AND_DISK_SER。
  二、基于Direct的方式
    替代掉使用Receiver来接收数据后，这种方式会周期性地查询Kafka，来获得每个topic+partition的最新的offset，从而定义每个batch的offset的范围。当处理数据的job启动时，就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。
    优点:
      1.简化并行读取：如果要读取多个partition，不需要创建多个输入DStream然后对它们进行union操作。Spark会创建跟Kafka partition一样多的RDD partition，并且会并行从Kafka中读取数据。所以在Kafka partition和RDD partition之间，有一个一对一的映射关系。
      2.高性能：如果要保证零数据丢失，在基于receiver的方式中，需要开启WAL机制。这种方式其实效率低下，因为数据实际上被复制了两份，Kafka自己本身就有高可靠的机制，会对数据复制一份，而这里又会复制一份到WAL中。而基于direct的方式，不依赖Receiver，不需要开启WAL机制，只要Kafka中作了数据的复制，那么就可以通过Kafka的副本进行恢复。
      3.一次且仅一次的事务机制：基于receiver的方式，是使用Kafka的高阶API来在ZooKeeper中保存消费过的offset的。这是消费Kafka数据的传统方式。这种方式配合着WAL机制可以保证数据零丢失的高可靠性，但是却无法保证数据被处理一次且仅一次，可能会处理两次。因为Spark和ZooKeeper之间可能是不同步的。
      4.降低资源。Direct不需要Receivers，其申请的Executors全部参与到计算任务中；而Receiver-based则需要专门的Receivers来读取Kafka数据且不参与计算。因此相同的资源申请，Direct 能够支持更大的业务。
      5.降低内存。Receiver-based的Receiver与其他Exectuor是异步的，并持续不断接收数据，对于小业务量的场景还好，如果遇到大业务量时，需要提高Receiver的内存，但是参与计算的Executor并无需那么多的内存。而Direct 因为没有Receiver，而是在计算时读取数据，然后直接计算，所以对内存的要求很低。实际应用中我们可以把原先的10G降至现在的2-4G左右。
      6.鲁棒性更好.Receiver-based方法需要Receivers来异步持续不断的读取数据，因此遇到网络、存储负载等因素，导致实时任务出现堆积，但Receivers却还在持续读取数据，此种情况很容易导致计算崩溃。Direct 则没有这种顾虑，其Driver在触发batch 计算任务时，才会读取数据并计算。队列出现堆积并不会引起程序的失败。

      总结:
        1.基于direct的方式，使用kafka的简单api，Spark Streaming自己就负责追踪消费的offset，并保存在checkpoint中。Spark自己一定是同步的，因此可以保证数据是消费一次且仅消费一次。
        2.在Receiver的方式中，ssc中的partition和kafka中的partition并不是相关的，所以如果我们加大每个topic的partition数量，仅仅是增加线程来处理由单一Receiver消费的主题。但是这并没有增加Spark在处理数据上的并行度。
        3.对于不同的Group和topic我们可以使用多个Receiver创建不同的Dstream来并行接收数据，之后可以利用union来统一成一个Dstream。
        4.而在Direct方式中，Kafka中的partition与RDD中的partition是一一对应的并行读取Kafka数据，会创建和kafka分区一样的rdd个数。
        5.设置“spark.streaming.blockInterval”参数：接收的数据被存储在 Spark 内存前，会被合并成 block，而 block 数量决定了Task数量;举例，当批次时间间隔为2秒且 block 时间间隔为200毫秒时，Task 数量约为10;如果Task数量过低，则浪费了 CPU 资源;推荐的最小block时间间隔为50毫秒。
17.windows操作
  window(windowLength, slideInterval)
  countByWindow(windowLength, slideInterval)
  reduceByWindow(func, windowLength, slideInterval)
  reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks]):val windowWords = pairs.reduceByKeyAndWindow((a: Int, b:Int ) => (a + b) , (a:Int, b: Int) => (a - b) , Seconds( 3 ), Seconds( 1 ))
  reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval, [numTasks])
  countByValueAndWindow(windowLength, slideInterval, [numTasks])
18.Join Operations
  a.Stream-stream joins
    val windowedStream1 = stream1.window(Seconds(20))
    val windowedStream2 = stream2.window(Minutes(1))
    val joinedStream = windowedStream1.join(windowedStream2)
    支持:leftOuterJoin/rightOuterJoin/fullOuterJoin
  b.Stream-dataset joins
  val dataset: RDD[String, String] = ...
  val windowedStream = stream.window(Seconds(20))...
  val joinedStream = windowedStream.transform { rdd => rdd.join(dataset) }
  c.输出
  dstream.foreachRDD { rdd =>
  rdd.foreachPartition { partitionOfRecords =>
    val connection = createNewConnection()
    partitionOfRecords.foreach(record => connection.send(record))
    connection.close()
  }
}
19.窄依赖和宽依赖
  窄依赖是指父rdd的分区最多被一个子rdd的分区使用，即一个父rdd的分区对应一个rdd的分区，或者多个父rdd的分区对应一个子rdd分区;
  宽依赖是指子rdd的分区依赖于父rdd的多个分区或者所有分区
20.repartition和coalesce的区别
  repartition(numPartitions:Int)和coalesce(numPartitions:Int，shuffle:Boolean=false):对rdd的分区进行重新分区，repartition内部调用了coalesce，参数shuffle为true
  例：RDD有N个分区，需要重新划分成M个分区
1. N小于M
  一般情况下N个分区有数据分布不均匀的状况，利用HashPartitioner函数将数据重新分区为M个，这时需要将shuffle设置为true。
2. N大于M且和M相差不多
  假如N是1000，M是100)那么就可以将N个分区中的若干个分区合并成一个新的分区，最终合并为M个分区，这时可以将shuff设置为false，在shuffl为false的情况下，如果M>N时，coalesce为无效的，不进行shuffle过程，父RDD和子RDD之间是窄依赖关系。
3. N大于M且和M相差悬殊
  这时如果将shuffle设置为false，父子RDD是窄依赖关系，他们在同一个Stage中，就可能造成Spark程序的并行度不够，从而影响性能，如果在M为1的时候，为了使coalesce之前的操作有更好的并行度，可以讲shuffle设置为true。

总结：返回一个减少到numPartitions个分区的新RDD，这会导致窄依赖，例如：你将1000个分区转换成100个分区，这个过程不会发生shuffle，相反如果10个分区转换成100个分区将会发生shuffle。然而如果你想大幅度合并分区，例如所有partition合并成一个分区，这会导致计算在少数几个集群节点上进行（言外之意：并行度不够）。为了避免这种情况，你可以将第二个shuffle参数传递一个true，这样会在重新分区过程中多一步shuffle，这意味着上游的分区可以并行运行。

总之：如果shuff为false时，如果传入的参数大于现有的分区数目，RDD的分区数不变，也就是说不经过shuffle，是无法将RDD的partition数变多的

21.spark的基础优化
  一、开发调优
    1.避免重复创建RDD
    2.尽可能重用同一个RDD
    3.对多次重用的RDD进行持久化操作
    MEMORY_ONLY	使用未序列化的Java对象格式，将数据保存在内存中。如果内存不够存放所有的数据，则数据可能就不会进行持久化。那么下次对这个RDD执行算子操作时，那些没有被持久化的数据，需要从源头处重新计算一遍。这是默认的持久化策略，使用cache()方法时，实际就是使用的这种持久化策略。
    MEMORY_AND_DISK	使用未序列化的Java对象格式，优先尝试将数据保存在内存中。如果内存不够存放所有的数据，会将数据写入磁盘文件中，下次对这个RDD执行算子时，持久化在磁盘文件中的数据会被读取出来使用。
    MEMORY_ONLY_SER	基本含义同MEMORY_ONLY。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。
    MEMORY_AND_DISK_SER	基本含义同MEMORY_AND_DISK。唯一的区别是，会将RDD中的数据进行序列化，RDD的每个partition会被序列化成一个字节数组。这种方式更加节省内存，从而可以避免持久化的数据占用过多内存导致频繁GC。
    DISK_ONLY	使用未序列化的Java对象格式，将数据全部写入磁盘文件中。
    MEMORY_ONLY_2, MEMORY_AND_DISK_2, 等等.	对于上述任意一种持久化策略，如果加上后缀_2，代表的是将每个持久化的数据，都复制一份副本，并将副本保存到其他节点上。这种基于副本的持久化机制主要用于进行容错。假如某个节点挂掉，节点的内存或磁盘中的持久化数据丢失了，那么后续对RDD计算时还可以使用该数据在其他节点上的副本。如果没有副本的话，就只能将这些数据从源头处重新计算一遍了。

    默认情况下，性能最高的当然是MEMORY_ONLY，但前提是你的内存必须足够足够大，可以绰绰有余地存放下整个RDD的所有数据。因为不进行序列化与反序列化操作，就避免了这部分的性能开销；对这个RDD的后续算子操作，都是基于纯内存中的数据的操作，不需要从磁盘文件中读取数据，性能也很高；而且不需要复制一份数据副本，并远程传送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种策略的场景还是有限的，如果RDD中数据比较多时（比如几十亿），直接用这种持久化级别，会导致JVM的OOM内存溢出异常。
    如果使用MEMORY_ONLY级别时发生了内存溢出，那么建议尝试使用MEMORY_ONLY_SER级别。该级别会将RDD数据序列化后再保存在内存中，此时每个partition仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别比MEMORY_ONLY多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问题同上，如果RDD中的数据量过多的话，还是可能会导致OOM内存溢出的异常。
    如果纯内存的级别都无法使用，那么建议使用MEMORY_AND_DISK_SER策略，而不是MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。
    通常不建议使用DISK_ONLY和后缀为_2的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，有时还不如重新计算一次所有RDD。后缀为_2的级别，必须将所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性能开销，除非是要求作业的高可用性，否则不建议使用。
    4.尽量避免使用shuffle类算子
    5.使用map-side预聚合的shuffle操作
      所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较
    6.使用高性能的算子
      使用reduceByKey/aggregateByKey替代groupByKey
      使用mapPartitions替代普通map
      使用foreachPartitions替代foreach
      使用filter之后进行coalesce操作
      使用repartitionAndSortWithinPartitions替代repartition与sort类操作:repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。
    7.广播大变量
    8.使用Kryo优化序列化性能
      以下使用序列化:
        1.在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输;例如广播大变量
        2.将自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口
        3.使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。
        // 创建SparkConf对象。
        val conf = new SparkConf().setMaster(...).setAppName(...)
        // 设置序列化器为KryoSerializer。
        conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
        // 注册要序列化的自定义类型。
        conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
    9.优化数据结构
      Java中，有三种类型比较耗费内存：
        1.对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。
        2.字符串，每个字符串内部都有一个字符数组以及长度等额外信息。
        3.集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如Map.Entry。
22.资源调优
  num-executors
  参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。
  参数调优建议：每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。
  executor-memory
  参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。
  参数调优建议：每个Executor进程的内存设置4G~8G较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，num-executors乘以executor-memory，就代表了你的Spark作业申请到的总内存量（也就是所有Executor进程的内存总和），这个量是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的总内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。
  executor-cores
  参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。
  参数调优建议：Executor的CPU core数量设置为2~4个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么num-executors * executor-cores不要超过队列总CPU core的1/3~1/2左右比较合适，也是避免影响其他同学的作业运行。
  driver-memory
  参数说明：该参数用于设置Driver进程的内存。
  参数调优建议：Driver的内存通常来说不设置，或者设置1G左右应该就够了。唯一需要注意的一点是，如果需要使用collect算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。
  spark.default.parallelism
  参数说明：该参数用于设置每个stage的默认task数量。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。
  参数调优建议：Spark作业的默认task数量为500~1000个较为合适。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行，也就是白白浪费了资源！因此Spark官网建议的设置原则是，设置该参数为num-executors * executor-cores的2~3倍较为合适，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。
  spark.storage.memoryFraction
  参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。
  参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。
  spark.shuffle.memoryFraction
  参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是0.2。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。
  参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。
  资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。
  ./bin/spark-submit \
    --master yarn-cluster \
    --num-executors 100 \
    --executor-memory 6G \
    --executor-cores 4 \
    --driver-memory 1G \
    --conf spark.default.parallelism=1000 \
    --conf spark.storage.memoryFraction=0.5 \
    --conf spark.shuffle.memoryFraction=0.3 \

23.数据倾斜处理的方法
解决方案一：使用Hive ETL预处理数据
方案适用场景：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。

方案实现思路：此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。

方案实现原理：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。

方案优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。

方案缺点：治标不治本，Hive ETL中还是会发生数据倾斜。

方案实践经验：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。

项目实践经验：在美团·点评的交互式用户行为分析系统中使用了这种方案，该系统主要是允许用户通过Java Web系统提交数据分析统计任务，后端通过Java提交Spark作业进行数据分析统计。要求Spark作业速度必须要快，尽量在10分钟以内，否则速度太慢，用户体验会很差。所以我们将有些Spark作业的shuffle操作提前到了Hive ETL中，从而让Spark直接使用预处理的Hive中间表，尽可能地减少Spark的shuffle操作，大幅度提升了性能，将部分作业的性能提升了6倍以上。

解决方案二：过滤少数导致倾斜的key
方案适用场景：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。

方案实现思路：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。

方案实现原理：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。

方案优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。

方案缺点：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。

方案实践经验：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天Spark作业在运行的时候突然OOM了，追查之后发现，是Hive表中的某一个key在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个key之后，直接在程序中将那些key给过滤掉。

解决方案三：提高shuffle操作的并行度
方案适用场景：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。

方案实现思路：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。对于Spark SQL中的shuffle类语句，比如group by、join等，需要设置一个参数，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，该值默认是200，对于很多场景来说都有点过小。

方案实现原理：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。具体原理如下图所示。

方案优点：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。

方案缺点：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。

方案实践经验：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个key对应的数据量有100万，那么无论你的task数量增加到多少，这个对应着100万数据的key肯定还是会分配到一个task中去处理，因此注定还是会发生数据倾斜的。所以这种方案只能说是在发现数据倾斜时尝试使用的第一种手段，尝试去用嘴简单的方法缓解数据倾斜而已，或者是和其他方案结合起来使用。

解决方案四：两阶段聚合（局部聚合+全局聚合）
方案适用场景：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。

方案实现思路：这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。

方案实现原理：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。

方案优点：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。

方案缺点：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。

解决方案五：将reduce join转为map join
方案适用场景：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。

方案实现思路：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。

方案实现原理：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。

方案优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。

方案缺点：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。

解决方案六：采样倾斜key并分拆join操作
方案适用场景：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。

方案实现思路：

对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。
然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀，而不会导致倾斜的大部分key形成另外一个RDD。
接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀，不会导致倾斜的大部分key也形成另外一个RDD。
再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。
而另外两个普通的RDD就照常join即可。
最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。
方案实现原理：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。

方案优点：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。

方案缺点：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。

解决方案七：使用随机前缀和扩容RDD进行join
方案适用场景：如果在进行join操作时，RDD中有大量的key导致数据倾斜，那么进行分拆key也没什么意义，此时就只能使用最后一种方案来解决问题了。

方案实现思路：

该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。
然后将该RDD的每条数据都打上一个n以内的随机前缀。
同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。
最后将两个处理后的RDD进行join即可。
方案实现原理：将原先一样的key通过附加随机前缀变成不一样的key，然后就可以将这些处理后的“不同key”分散到多个task中去处理，而不是让一个task处理大量的相同key。该方案与“解决方案六”的不同之处就在于，上一种方案是尽量只对少数倾斜key对应的数据进行特殊处理，由于处理过程需要扩容RDD，因此上一种方案扩容RDD后对内存的占用并不大；而这一种方案是针对有大量倾斜key的情况，没法将部分key拆分出来进行单独处理，因此只能对整个RDD进行数据扩容，对内存资源要求很高。

方案优点：对join类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。

方案缺点：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个RDD进行扩容，对内存资源要求很高。

方案实践经验：曾经开发一个数据需求的时候，发现一个join导致了数据倾斜。优化之前，作业的执行时间大约是60分钟左右；使用该方案优化之后，执行时间缩短到10分钟左右，性能提升了6倍。
