Executor GC

对于gc time ratio过高的情况，进行定位排查，这种情况与文件格式，sql code的类型、sql编写方式不合理、exector内存分配不合理等相关。
具体举例：
1.对于orc表使用select * 的情况，因为selelct * orc默认会扫描所有列造成大量内存消耗以及sql性能低下；因此需要将select *修改为select 具体字段；
2.spark job数据量过大造成gc高发；解决方案进行数据量减少，通过分区过滤、字段pushdown，sql分拆等方式进行数据量降低。
3.exector内存不足造成；解决方案加大exector运行内存;现在大集群spark2.1.1默认exector内存为6G，2.3.2的是5G;
设置exector内存方式：这里将sql2的executormemory调整大为6g，在sql2之后再将executormemory调整会默认的5g，避免对sql2之后的sql产生影响。
#####sql1#####
set spark.executor.memory=6g;
#####sql2#####
set spark.executor.memory=5g;
#####sql3#####


Executor spill

对于spill数据量超限制的情况，需要调整Executor内存相关的参数来进行解决：
优化方案：
1.调整executor内存相关参数
（1）增加spark.executor.memory内存
解决方案加大exector运行内存;现在大集群spark2.1.1默认exector内存为6G，2.3.2的是5G;
设置exector内存方式：这里将sql2的executormemory调整大为6g，在sql2之后再将executormemory调整会默认的5g，避免对sql2之后的sql产生影响。
#####sql1#####
set spark.executor.memory=6g;
#####sql2#####
set spark.executor.memory=5g;
#####sql3#####
2.问题排查定位，查看jvm内存消耗情况，确定问题进行调优。
举例：
 (1)对于orc表使用select * 的情况，因为selelct * orc默认会扫描所有列造成大量内存消耗以及sql性能低下；因此需要将select *修改为select 具体字段；
(2)非orc的表修改为orc格式：
临时表修改方式：wiki链接：临时表切换orc方式
（3）数据量过大，解决方案进行数据量减少，通过分区过滤、字段pushdown，sql分拆等方式进行数据量降低。
小tips:
具体查看spark sql失败日志以及spark job history 使用方法查看具体job task失败原因（代理配置方式）
wiki链接:SparkSQL使用总结#%E8%AF%BB%E6%87%82sparksql%E8%BF%90%E8%A1%8C%E6%97%A5%E5%BF%97


spark conf

spark.yarn.executor.memoryOverhead>3.5G则告警
用户需要将该参数值调小为3.5G以下，不包括3.5G；

若小于3.5G报错，则进行问题排查定位

具体定位方法：

1.调整spark.yarn.executor.memoryOverhead参数，重新运行该sql，查看任务是否会报错，修改方式如下：

现在线上spark.yarn.executor.memoryOverhead默认为3G，

减少memoryOverhead为默认的3G;

调整会默认值，避免对sql2之后的sql产生影响。

#####sql1#####

set spark.yarn.executor.memoryOverhead=3G;

#####sql2#####

#####sql3#####

2.问题排查定位，查看jvm内存消耗情况，确定问题进行调优。

(1)对于orc表使用select * 的情况，因为selelct * orc默认会扫描所有列造成

大量内存消耗以及sql性能低下；因此需要将select *修改为select 具体字段；

(2)非orc的表修改为orc格式：

临时表修改方式：wiki链接：临时表切换orc方式

（3）数据量过大，解决方案进行数据量减少，通过分区过滤、

字段pushdown，sql分拆等方式进行数据量降低。

小tips:
具体查看spark sql失败日志以及spark job history 使用方法查看

Spark Executor Metrics

单个exector cache的数据量，
现在大集群spark2.1.1默认exector内存为6G，2.3.2的是5G;
对于executor过多cache数据的情况，

比如超过2G以上，会引起task执行性能变慢，

所有对于告警这种情况需要用户减少

cache数据量或者只cache较小的表；


Spark Job Metrics

jobFailureRateSeverity
查看spark job中失败job，定位失败job原因进行解决；
如果出现这种问题大部分是由于引擎不稳定
或者sql code本身执行错误引起，需要查看失败的job的具体
原因。
举例：
之前出现的job失败由于job中大量的task失败引起。

taskFailureRateSeverities
查看spark app job中失败task，定位失败task原因进行解决；
如果出现这种问题大部分是由于引擎不稳定或者sql code
本身执行错误引起,需要查看失败的task的具体
原因。
举例：
task失败可能与sql语法错误、task处理的数据量
过大造成超时失败、task数据倾斜引起。


Spark Stages with failed tasks


severityOOM
优化方案：
1.调整executor内存相关参数
（1）增加spark.executor.memory内存
解决方案加大exector运行内存;现在大集群spark2.1.1默认exector内存为6G，2.3.2的是5G;
设置exector内存方式：这里将sql2的executormemory调整大为6g，

在sql2之后再将executormemory调整会默认的5g，避免对sql2之后的sql产生影响。
#####sql1#####
set spark.executor.memory=6g;
#####sql2#####
set spark.executor.memory=5g;
#####sql3#####
（2）增加spark.memory.fraction内存比例
现在spark.memory.fraction默认为0.75；

通过set spark.memory.fraction = xxx进行调整；
（3）增加executor cores个数
现在spark.executor.cores默认为4个；
通过set spark.executor.cores = x进行调整；


severityOverhead
1.调整spark.yarn.executor.memoryOverhead参数

现在线上spark.yarn.executor.memoryOverhead默认为3G，

增加memoryOverhead在默认的基础上每次递增1G;

这里将sql2的memoryOverhead增加1G，在sql2之后再将memoryOverhead

调整会默认值，避免对sql2之后的sql产生影响。

#####sql1#####

set spark.yarn.executor.memoryOverhead=4G;

#####sql2#####

set spark.yarn.executor.memoryOverhead=3G;

#####sql3#####

2.问题排查定位，查看jvm内存消耗情况，确定问题进行调优。

(1)对于orc表使用select * 的情况，因为selelct * orc默认会扫描所有列造成

大量内存消耗以及sql性能低下；因此需要将select *修改为select 具体字段；

(2)非orc的表修改为orc格式：

临时表修改方式：wiki链接：临时表切换orc方式

（3）数据量过大，解决方案进行数据量减少，通过分区过滤、

字段pushdown，sql分拆等方式进行数据量降低。

小tips:
具体查看spark sql失败日志以及spark job history 使用方法查看
