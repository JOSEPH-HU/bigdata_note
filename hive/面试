1.hive表的类型
  a.内部表和外部表的区别
    创建表：外部表创建表的时候，不会移动到数据仓库目录中，只会记录表数据存放的路径;内部表会把数据保存到数仓目录下
    删除表:外部表只会删除表的元数据信息而不会删除表数据;内部表会删除元数据和表数据
  b.分区表:分区表创建表的时候需要指定分区字段，分区字段和普通字段的区别：分区字段会在hdfs表目录下生成一个分区字段名称的目录，而普通字段则不会。
  c.桶表:将内部表、外部表和分区表进一步组织成桶表,可以将表的列同hash算法进一步分解成不同的存储文件
2.hive自定义函数
  UDF:一进一出
  UDAF:多进一出
  UDTF:一进多出
3.4种排序
  a.order by:对输入做全局排序，因此只有一个reducer
  b.sort by(对分区内的数据进行排序):sort by不是全局排序，其在数据进入reducer前完成排序，因此，如果用sort by进行排序，并且设置mapred.reduce.tasks>1，则sort by只会保证每个reducer的输出有序，并不保证全局有序。sort by不同于order by，它不受Hive.mapred.mode属性的影响，sort by的数据只能保证在同一个reduce中的数据可以按指定字段排序。使用sort by你可以指定执行的reduce个数(通过set mapred.reduce.tasks=n来指定)，对输出的数据再执行归并排序，即可得到全部结果。
  c.distribute by(对map输出进行分区):distribute by是控制在map端如何拆分数据给reduce端的。hive会根据distribute by后面列，对应reduce的个数进行分发，默认是采用hash算法。sort by为每个reduce产生一个排序文件。在有些情况下，你需要控制某个特定行应该到哪个reducer，这通常是为了进行后续的聚集操作。distribute by刚好可以做这件事。因此，distribute by经常和sort by配合使用。
  d.cluster by :cluster by除了具有distribute by的功能外还兼具sort by的功能。当distribute by和sort by 是同一个字段的时候可以使用cluster by替代。但是排序只能是倒叙排序，不能指定排序规则为ASC或者DESC。
4.局部分组排序
  a.row_number：不管col2字段的值是否相等，行号一直递增，比如：有两条记录的值相等，但一个是第一，一个是第二
  b.rank：上下两条记录的col2相等时，记录的行号是一样的，但下一个col2值的行号递增N（N是重复的次数），比如：有两条并列第一，下一个是第三，没有第二
  c.dense_rank：上下两条记录的col2相等时，下一个col2值的行号递增1，比如：有两条并列第一，下一个是第二
5.hive优化
  a.fetch task任务不走MapReduce，可以在hive配置文件中设置最大化和最小化fetch task任务,set hive.fetch.task.conversion=more;   //单次交互模式下有效，或者bin/hive --hiveconf hive.fetch.task.conversion=more
  b.strict mode：严格模式设置，严格模式下将会限制一些查询操作,hive.mapred.mode=strict;a：当表为分区表时，where字句后没有分区字段和限制时，不允许执行。b：当使用order by语句时，必须使用limit字段，因为order by 只会产生一个reduce任务;c：限制笛卡尔积的查询。sql语句不加where不会执行
  c.限制临时数据目录的大小
  d.优化sql语句，如先过滤再join，先分组再做distinct;
  e.MapReduce过程的map、shuffle、reduce端的snappy压缩;set mapreduce.output.fileoutputformat.compress=true;set mapreduce.output.fileoutputformat.compress.codec=org apache.hadoop.io.compress.SnappyCodec;
  f.大表拆分成子表，提取中间结果集，减少每次加载数据.多维度分析，多个分析模块;每个分析模块涉及字段不一样，而且并不是表的全部字段
  g.设置map和reduce个数：默认情况下一个块对应一个map任务，map数据我们一般不去调整，reduce个数根据reduce处理的数据量大小进行适当调整体现“分而治之”的思想
  k.JVM重用：一个job可能有多个map reduce任务，每个任务会开启一个JVM虚拟机，默认情况下一个任务对应一个JVM，任务运行完JVM即销毁，我们可以设置JVM重用参数，一般不超过5个，这样一个JVM内可以连续运行多个任务.set mapred.job.reuse.jvm.num.tasks=10;
  l.推测执行：例如一个Job应用有10个MapReduce任务（map 及reduce），其中9个任务已经完成，那么application Master会在另外启动一个相同的任务来运行未完成的那个，最后哪个先运行完成就把另一个kill掉.hive.mapred.reduce.tasks.speculative.execution=true;
6.数据倾斜
  当数据量比较大时，并且key分布不均匀，大量的key都shuffle到一个reduce上，就出现数据倾斜,常见的数据倾斜出现在group by和join on语句中
  a.join数据倾斜
    a1.在进行两个表join的过程中，由于hive都是从左向右执行，要注意将小表在前，大表在后.
    如果是group by过程出现倾斜应将此项设置true。hive.groupby.skewindata;如果是join 过程中出现倾斜应将此项设置为true,hive.optimize.skewjoin.compiletime;hive.optimize.skewjoin.compiletime=true; 如果是join过程出现倾斜应该设置为true
    此时会将join语句转化为两个mapreduce任务，第一个会给jion字段加随机散列
    set hive.skewjoin.key=100000; 这个是join的键对应的记录条数超过这个值则会进行优化。
    空值太多或者类型不一致（join）
  b.Map-side Join
    当join两个表时，其中一个表是小表和另一个表是大表，我们可以直接把小表直接放到内存中,然后再对比较大的表进行map操作。join就发生在map操作阶段，
    set hive.auto.convert.join=true;set hive.auto.convert.join.noconditionaltask.size=10000000 样设置，hive就会自动的识别比较小的表，继而用mapJoin来实现两个表的联合。看看下面的两个表格的连接。
    select /+mapjoin(A)/ f.a,f.b from A t join B f on(f.a==t.a);set hive.auto.convert.join=true;hive.mapjoin.smalltable.filesize=25;默认值是25mb
  c.Reduce-side Join
    在map阶段，map函数同时读取两个文件File1和File2，为了区分两种来源的key/value数据对，对每条数据打一个标签（tag）
  d.SMB Join（sort merge bucket)首先进行排序，继而合并，然后放到所对应的bucket中去，bucket是hive中和分区表类似的技术，就是按照key进行hash，  相同的hash值都放到相同的buck中去。在进行两个表联合的时候。我们首先进行分桶，在join会大幅度的对性能进行优化。也就是说，在进行联合的时候，  是table1中的一小部分和table1中的一小部分进行联合，table联合都是等值连接，相同的key都放到了同一个bucket中去了，那么在联合的时候就会大幅度的减小无关项的扫描。
  set hive.auto.convert.sortmerge.join=true;
  set hive.optimize.bucketmapjoin = true;
  set hive.optimize.bucketmapjoin.sortedmerge = true;
  set hive.auto.convert.sortmerge.join.noconditionaltask=true;
  create table emp_info_bucket(ename string,deptno int)
  partitioned by (empno string)
  clustered by(deptno) into 4 buckets;

  insert overwrite table emp_info_bucket
  partition (empno=7369)
  select ename ,deptno from emp

  create table dept_info_bucket(deptno string,dname string,loc string)
  clustered by (deptno) into 4 buckets;

  insert overwrite table dept_info_bucket
  select * from dept;
  select * from emp_info_bucket emp  join dept_info_bucket dept
  on(emp.deptno==dept.deptno);//正常的情况下，应该是启动smbjoin的但是这里的数据量太小啦，还是启动了mapjoin
  from trackinfo a
处理数据倾斜：随机数
left outer join pm_info b
on (
case when (a.ext_field7 is not null
and length(a.ext_field7) > 0
and a.ext_field7 rlike ‘^[0-9]+$’)
then
cast(a.ext_field7 as bigint)
else
cast(ceiling(rand() * -65535) as bigint)
end = b.id
)

7.hive的工作原理
  a.用户提交查询等操作给Driver
  b.编译器获得该用户的任务plan
  c.编译器Compiler根据用户任务去MetaStore中获取需要的hive的元数据信息
  d.编译器Compiler得到元数据信息，对任务进行编译，先将hiveQL转换成抽象语法树，然后将抽象语法树转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划（MR），最后选择最佳的策略
  e.将最终的计划提交给Driver
  f.Driver将计划Plan转交给ExecutionEngine去执行，获取元数据信息，将最终的计划提交给rSourceManager执行该任务，任务会直接读取HDFS中文件进行相应的操作。
  g.获取执行的结果
  k.取得并返回执行结果
8.优化器的主要功能：
  1. 将多Multiple join 合并为一个Muti-way join
  2. 对join、group-by和自定义的MapReduce操作重新进行划分。
  3. 消减不必要的列。
  4. 在表的扫描操作中推行使用断言。
  5. 对于已分区的表，消减不必要的分区。
  6. 在抽样查询中，消减不必要的桶。
  7. 优化器还增加了局部聚合操作用于处理大分组聚合和增加再分区操作用于处理不对称的分组聚合。
9.编译器的过程
  a.将hql转换成抽象语法树
  b.将抽象语法树转化为查询块
  c.将查询块转化为逻辑查询计划
  d.重写逻辑查询计划
  e.将逻辑查询计划转化为物理查询计划
  f.选择最佳策略
